# Question

Decide if the given statmen is true or false.

"The aim of analysing metafiles is to identify hidden or obfuscated paths, functionality and map other information that could lead to a better understanding of the systems."

* ( ) True
* ( ) False

-----SPLIT-----

# Answer

* (x) True
* ( ) False


-----SPLIT-----

# Question

Decide if the given statmen is true or false.

"In Robot Exclusion Protocol, the User-Agent directive refers to the specific web spider/robot/crawler."

* ( ) True
* ( ) False

-----SPLIT-----

# Answer

* (x) True
* ( ) False

Explanation: User-Agent: Googlebot refers to the spider from Google while User-Agent: bingbot refers to a crawler from Microsoft. User-Agent: * applies to all web spiders/robots/crawlers.

-----SPLIT-----

# Question

Decide if the given statmen is true or false.

"In Robot Exclusion Protocol, the 'Disallow' directive specifies which resources are prohibited by spiders/robots/crawlers"

* ( ) True
* ( ) False

-----SPLIT-----

# Answer

* (x) True
* ( ) False

Explanation: 'Disallow: /search' in robots.txt file means the bots are prohibitied to access the '/search' resource.


-----SPLIT-----

# Question

Decide if the given statmen is true or false.

"In Robot Exclusion Protocol, the 'Disallow' directive *ensures* that resources are secured and therefore cannot be accessed by spiders/robots/crawlers."

* ( ) True
* ( ) False

-----SPLIT-----

# Answer

* ( ) True
* (x) False

Explanation: Web spiders/robots/crawlers can intentionally ignore the Disallow directives specified in a robots.txt file. Hence, robots.txt should not be considered as a mechanism to enforce restrictions on how web content is accessed, stored, or republished by third parties.

-----SPLIT-----

# Question

Which of the followings are metafiles in a web application? Can choose multiple answers.

* ( ) Robots.txt
* ( ) Sitemaps.xml
* ( ) Security.txt
* ( ) Humans.txt
* ( ) None of the above 

-----SPLIT-----

# Answer

* (x) Robots.txt
* (x) Sitemaps.xml
* (x) Security.txt
* (x) Humans.txt
* ( ) None of the above 
